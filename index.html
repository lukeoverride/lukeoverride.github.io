<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Luca Src</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
                <nav>
                    <ul>
                        <li><a href="index.html" class="active">Home</a></li>
                        <li><a href="gaming.html">Gaming</a></li>
                        <li><a href="blog.html">Blog</a></li>
                        <li><a href="misc.html">Miscellaneous</a></li>
                    </ul>
				</nav>
				<header>
					<span class="image avatar"><img src="images/frick.jpg" alt="" /></span>
					<h1 id="logo"><a href="#">Luca Surace</a></h1>
					<p>PhD in Computer Graphics & Human Perception</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about" class="active">About</a></li>
						<li><a href="#research">Research</a></li>
						<li><a href="#publications">Publications</a></li>
						<li><a href="#teaching">Teaching</a></li>
					</ul>
				</nav>
				<footer>
                    <ul class="icons">
                        <li><a href="https://scholar.google.it/citations?user=UZeU9wIAAAAJ&hl=it" class="icon brands fa fa-google"><span class="label">Scholar</span></a></li>
                        <li><a href="https://github.com/lukeoverride" class="icon brands fa-github"><span class="label">Github</span></a></li>
                        <li><a href="mailto:luca.surace@usi.ch" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
                        <li><a href="https://www.linkedin.com/in/lukeoverride" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
                    </ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
                <div id="main">

                    <!-- One -->
                    <section id="about">
                        <!--
                        <div class="image main" data-position="center">
                            <img src="images/frattale.jpg" alt="" />
                        </div> -->
                        <div class="container">
                            <header class="major">
                                <h2>Luca's Studio</h2>
                                <p>I am a researcher in Computer Graphics & Human Perception</p>
                                <p>
                                    In this website I occasionally publish some info about my research and extra stuff that I do or I like, e.g. gaming prototypes, music, teaching, sport... <br />
                                </p>
                            </header>
                            <p>This "studio" is intended as a half way between a personal page and a blog. Other than content on computer science, 
                            it is going to contain flashes of various topics.
                            </p>
                        </div>
                    </section>

                    <!-- Two -->
                    <section id="research">
                        <div class="container">
                            <h3>Research</h3>
                            <p>
                                My research focuses on creating models of different aspects of human vision to improve computer graphics techniques
                                in terms of both quality and efficiency, mainly but not exclusively for VR displays.<br />

                                I have worked on peripheral vision, color, luminance-contrast, and depth. 
                                These models have been applied respectively to the following corresponding applications: 
                                foveated rendering (image and geometry), color grading, power saving, and 3D reconstruction.
                                <br/>
                                I did my PhD in the <a href="https://www.pdf.inf.usi.ch">Perception, Display and Fabrication group</a> led by Prof. Piotr Didyk, 
                                at <a href="https://www.usi.ch">USI</a>-<a href="https://www.idsia.ch">IDSIA</a> in Lugano, Switzerland.
                                My doctoral thesis is available <a href=https://susi.usi.ch/usi/documents/332901>here</a>.

                                During my PhD, I had the opportunity to intern at <a href="https://studios.disneyresearch.com/">Disney Research|Studios</a> on color perception, supervised by 
                                <a href=https://studios.disneyresearch.com/people/tunc-aydin/>Dr. Tunç Aydin</a>;
                                and at <a href=https://arvr.google.com/>Google</a>, working on 3D reconstruction for stereoscopic rendering within the XR Core Tech Team,
                                supervised by <a href=https://core-lab.io/>Prof. Cengiz Öztireli</a>.

                                Before that, I worked on the <a href="https://en.wikipedia.org/wiki/Air-Cobot">Air-Cobot project</a> 
                                and obtained a MSc from <a href="https://www.unical.it/">University of Calabria</a> (Italy) with a thesis focusing on emotion recognition (<a href="https://www.plymouth.ac.uk/">University of Plymouth</a>, UK).
                            </p>

                            <h4>News</h4>
                            <ul>
                                <li>[Dec 2025] - I have been invited to participate in the <a href=https://www.humaneconomicforum.org/>Human Economic Forum</a> at the Italian Parliament, in Rome.</li>
                                <li>[Sept 2025] - I am officially a Doctor of Philosophy in Informatics!</li>
                                <li>[June 2025] - I presented our paper on brightness management at <a href="https://conferences.eg.org/egsr2025/">EGSR 2025</a>.</li>
                                <li>[May 2025] - I will soon be joining <a href=https://arvr.google.com/>Google Zurich</a> for a research internship. <img src=images/google.png height=24px> </li>
                                <li>[May 2025] - I have successfully defended my doctoral dissertation at USI. I am very glad for the large audience and particularly for the
                                presence of the external
                                 
                             
                                <div class="tooltip-container">
                                  committee
                                  <div class="tooltip-content">
                                      <a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a> (Advisor), USI</br>
                                      <a href="https://www.inf.usi.ch/hormann/">Kai Hormann</a>, USI <br/>
                                      <a href=https://search.usi.ch/it/persone/8ad62e7fa5453718517c654c013c13cb/papadopoulou-evanthia>Evanthia Papadopoulou</a>, USI <br/> 
                                      <a href="https://cwyman.org/">Chris Wyman</a>, NVIDIA <br/>
                                      <a href="https://qisun.me/">Qi Sun</a>, NYU<br/>
                                  </div>
                                </div>

                                members who traveled a long way to be in Lugano.



                                <li>[June 2024] - I gave a talk on foveated rendering at the <a href="https://devgames.org/en/2024.html">2024 Italian Conference on Game Development</a>, Rome.
                                I will be present also in <a href="https://devgames.org/en/index.html">2025</a>, at <a href=https://www.uniroma3.it/>Università Roma Tre</a>.</li>
                                <li>[June 2024] - I am doing a three months internship at <a href="https://studios.disneyresearch.com/">Walt Disney Research Studios</a>, focusing on color perception. <img src=images/DRS.jpg height=24px></li>
                                <li>[Feb 2024] - Our lab was featured on the Swiss news multiple times. You can check the articles from <a href="https://www.swissinfo.ch/eng/sci-tech/virtual-reality-without-nausea-how-far-has-research-progressed/48575376">SwissInfo</a>,
                                <a href="images/teleticino.mp4">Teleticino</a> and
                                <a href="https://www.ticinoscienza.ch/it/news.php?la-realta-ricreata-dai-computer-e-dagli-smartphone-non-deve-essere-piu-reale-della-realta">Ticino Scienza</a>.
                                </li>
                            </ul>
                        </div>
                    </section>

                    <!-- Three -->
                    <section id="publications">
                        <div class="container">
                            <h3>Publications</h3>

                           
                            <div class="features">
                                <!---
                                <article>
                                    <a href="https://susi.usi.ch/usi/documents/332901" class="image"><img src="images/usi.png" /></a>
                                    <div class="inner">
                                        <h4><a href="https://susi.usi.ch/usi/documents/332901">Optimizing Visual Quality and Efficiency for Immersive Graphics</a></h4>
                                        <p>
                                            Luca Surace supervised by <a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a></br>
                                            Committee: <a href="https://www.inf.usi.ch/hormann/">Kai Hormann</a>, 
                                            <a href=https://search.usi.ch/it/persone/8ad62e7fa5453718517c654c013c13cb/papadopoulou-evanthia>Evanthia Papadopoulou</a>, 
                                            <a href="https://cwyman.org/">Chris Wyman</a>, <a href="https://qisun.me/">Qi Sun</a><br/>
                                            <b>Doctoral Dissertation, 2025</b>
                                        </p>
                                    </div>
                                </article>
                                -->
                                <article>
                                    <a class="image"><img src="images/brightness.jpg" alt="" /></a>
                                    <div class="inner">
                                        <h4>Temporal Brightness Management for Immersive Content</h4>
                                        <p>
                                            Luca Surace, <a href="https://arcanous98.github.io/">Jorge Condor</a>, <a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a></br>
                                            <b>Eurographics Symposium on Rendering, 2025</b><br/>           
                                        Leveraging and extending low-level vision models to optimize energy consumption in VR displays, in two flavors: 
                                        an optimization process minimizing contrast loss for offline content, and a PID control-inspired scheme for real-time rendering.
                                        <br /><a class="page_link" href="https://www.pdf.inf.usi.ch/projects/BrightnessManagement/index.html">Project Page</a>
                                        &nbsp;&nbsp;<a class="publisher_link" href="https://diglib.eg.org/handle/10.2312/sr20251183">Publisher Page</a>
                                        </p>
                                    </div>
                                </article>

                                <article>
                                    <a class="image"><img src="images/sampling_blended_alt.png" alt="" /></a>
                                    <div class="inner">
                                        <h4>Learning GAN-Based Foveated Reconstruction to Recover Perceptually Important Image Features</h4>
                                        <p>
                                            Luca Surace, <a href="https://scholar.google.fr/citations?user=GAU_tSYAAAAJ">Marek Wernikowski</a>, <a href=https://visualcomputing.nl/cara/>Cara Tursun</a>, <a href="https://people.mpi-inf.mpg.de/~karol/">Karol Myszkowski</a>,
                                            <a href=https://sites.google.com/view/rdmantiuk/home>Radosław Mantiuk</a>, <a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a></br>
                                            <b>Transaction on Applied Perception, 2023 </b><br/>
                                        Generating missing parts of a sparse foveated image using a perceptual loss trained on a custom dataset,
                                        that reflects what the human visual system can tolerate,
                                        producing higher-quality hallucinations for peripheral observation.<br />
                                        <a class="page_link" href="https://www.pdf.inf.usi.ch/projects/LearningFoveatedReconstruction/index.html">Project Page</a>
                                        &nbsp;&nbsp;<a class="publisher_link" href="https://dl.acm.org/doi/full/10.1145/3583072">Publisher Page</a>
                                        </p>
                                    </div>
                                </article>


                                <article>
                                    <a class="image"><img src="images/LOD.jpg" alt=" " /></a>
                                    <div class="inner">
                                        <h4>Gaze-Contingent Perceptual Level of Detail Prediction</h4>
                                        <p>
                                            Luca Surace, <a href=https://visualcomputing.nl/cara/>Cara Tursun</a>, <a href=https://graphics.cs.hacettepe.edu.tr/>Ufuk Çelikcan</a>, <a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a>  <br />
                                            <b>Eurographics Symposium on Rendering, 2023</b><br/>
                                        A technique to select the suitable LoD of a given mesh in the visual field. It keeps the same perceived quality
                                        and improves computational efficiency of a gaze-contingent system by saving on the rendered number of polygons.
                                        Tested also in combination with Nanite from Unreal engine.<br />
                                        <a class="page_link" href="https://www.pdf.inf.usi.ch/projects/GazeContingentPerceptualLOD/">Project Page</a>
                                        &nbsp;&nbsp;<a class="publisher_link" href="https://diglib.eg.org/items/aaf28e15-dbab-43af-b553-85fb2f788546">Publisher Page</a>
                                        </p>
                                    </div>
                                </article>

                                <article>
                                    <a class="image"><img src="images/emotion.png" alt="" /></a>
                                    <div class="inner">
                                        <h4>Emotion Recognition in the wild using deep neural networks and Bayesian classifiers</h4>
                                        <p>
                                            Luca Surace, <a href=https://mpatacchiola.github.io/>Massimiliano Patacchiola</a>, <a href=https://www.bilgi.edu.tr/en/academic/staff/elena-battini-sonmez/>Elena Battini Sonmez</a>, <a href=https://www.mat.unical.it/spataro/>William Spataro</a>, <a href=https://research.manchester.ac.uk/en/persons/angelo.cangelosi/>Angelo Cangelosi</a> <br />
                                            <b>19th ACM International Conference on Multimodal Interaction (ICMI), 2017</b><br />
                                        A technique to recognize the emotion of a group of people from a picture taken in unconstrained settings. Based on standard CNN and Bayes' theorem,
                                        it infers an emotion category: positive, negative or neutral.
                                        <br />
                                        <a class="git_link" href="https://github.com/lukeoverride/deemotions">Code</a>
                                        &nbsp;&nbsp;<a class="publisher_link" href="https://dl.acm.org/doi/abs/10.1145/3136755.3143015">Publisher Page</a>
                                        </p>
                                    </div>
                                </article>
                                <article>
                                    <a class="image"><img src="images/vessels.png" alt="" /></a>
                                    <div class="inner">
                                        <h4>S-rep model for fundus image analysis</h4>
                                        <p>
                                            <a href=https://www.mat.unical.it/calimeri/>Francesco Calimeri</a>, <a href=https://scholar.google.com/citations?user=4z5jbx0AAAAJ>Claudio Stamile</a>, Luca Surace<br />
                                            <b>IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), 2017</b><br/>
                                            A 3D reconstruction of blood vessels from fundus eye images. 
                                            The technique detects longitudinal changes in vessel structure using statistical analysis based on a generalized PCA approach.
                                            <br />
                                        &nbsp;&nbsp;<a class="publisher_link" href="https://ieeexplore.ieee.org/abstract/document/8388623">Publisher Page</a>
                                        </p>
                                    </div>
                                </article>
                            </div>
                        </div>
                    </section>


                    <section id="teaching">
                        <div class="container">
                            <h3>Teaching</h3>
                            <p>
                                <ul>
                                    <li><a href="https://search.usi.ch/index.php/it/corsi/35265714/computer-graphics">FS 2019/2020 - FS 2022/2023: Computer Graphics</a></li>
                                    <p>You will do cool things like ray-tracing, cloth simulation and the legendary rendering competition (<a href="https://www.pdf.inf.usi.ch/rendering_competition/2022/">2022</a>, <a href="https://www.pdf.inf.usi.ch/rendering_competition/2023/">2023</a>).</p>
                                    <li><a href="https://search.usi.ch/it/corsi/35265662/computational-fabrication">SS 2019/2020, SS 2021/2022: Computational Fabrication</a></li>
                            <p>When you print a 3D object, not everything goes well. To know why and how to solve the problems, as well as <a href="http://mesh.brown.edu/desktop3dscan/ch5-structured.html">create a 3D model without a scanner</a>, you should attend this course.</p>
                                    <li><a href="https://www.inf.usi.ch/faculty/carzaniga/edu/algo21s/index.html">SS 2020/2021: Algorithms & Data Structures</a></li>
                            <p>I guess you would like to know how to implement a <a href="https://www.sortvisualizer.com/bubblesort/">bubble sort</a>.</p>
                                </ul>
                            </p>

                            <div class="features">
                            	<h4>Bachelor Projects for USI Students</h4>
		                        <article>
				                    <p>
				                    The objective of the bachelor's project is to develop an interactive tool for drawing 2D closed shapes.
				                    Each closed shape can be represented with a series of elliptic functions. </br>
				                    The higher the number of ellipses in the sequence, the more precise the approximation of the shape is (see the figure).
				                    The tool should, given the state of the current drawing:
				                    <ul>
				                    	<li>compute its representation;</li>
				                    	<li>find similar shapes through comparison with several pre-computed representations of shapes;</li>
				                    	<li>suggest the similar shapes to the artist;</li>
				                    </ul>
				                    no machine learning is required. </br>
				                    The tool should also have basic commands for drawing, such as pencil, pen, eraser, undo and redo.
				                    A similar system is <a href=https://www.autodraw.com/>Autodraw</a>. Possible extensions are clearly possible. </br>
				                    If interested, please contact me at my USI email. </br>
				                    <a class="image"><img src="images/ellittiche.jpg" alt="" /></a>
				                    </p>
		                        </article>
                            </div>


                        </div>
                    </section>

                </div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Luca Surace. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
